{"cells":[{"cell_type":"markdown","metadata":{"id":"GOviCBhbngLe"},"source":["# Ex1 - Getting and Knowing your Data"]},{"cell_type":"markdown","metadata":{"id":"cnVjy8OzngLf"},"source":["\n","### Step 1: Initialize PySpark Session\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"BWKS0Y-MngLg","outputId":"93b1004c-c1b4-4e7a-ceaa-6f1edd8e9cae"},"outputs":[{"name":"stderr","output_type":"stream","text":["your 131072x1 screen size is bogus. expect trouble\n","23/08/29 15:56:47 WARN Utils: Your hostname, SUSHAN resolves to a loopback address: 127.0.1.1; using 172.31.47.41 instead (on interface eth0)\n","23/08/29 15:56:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","23/08/29 15:56:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["# Create a Spark session\n","spark = SparkSession.builder.appName(\"Day1\").getOrCreate()\n"]},{"cell_type":"markdown","metadata":{"id":"ZsKpvtp0ngLh"},"source":["### Step 2: Load the Dataset\n","\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8HqS9YFLngLh"},"outputs":[],"source":["# Load the Chipotle dataset into a Spark DataFrame\n","data_path = 'chipotle.csv' # Replace with the actual path\n","df = spark.read.csv(data_path, header=True, inferSchema=True)\n"]},{"cell_type":"markdown","metadata":{"id":"UPy0RQ34ngLh"},"source":["### Step 3. Get an overview of the DataFrame:\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- _c0: integer (nullable = true)\n"," |-- order_id: integer (nullable = true)\n"," |-- quantity: integer (nullable = true)\n"," |-- item_name: string (nullable = true)\n"," |-- choice_description: string (nullable = true)\n"," |-- item_price: string (nullable = true)\n","\n"]}],"source":["df.printSchema()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"PPQhClvongLh","outputId":"18720dbf-83aa-4d92-9569-8d1c4785f405"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+--------+--------+--------------------+--------------------+----------+\n","|_c0|order_id|quantity|           item_name|  choice_description|item_price|\n","+---+--------+--------+--------------------+--------------------+----------+\n","|  0|       1|       1|Chips and Fresh T...|                null|    $2.39 |\n","|  1|       1|       1|                Izze|        [Clementine]|    $3.39 |\n","|  2|       1|       1|    Nantucket Nectar|             [Apple]|    $3.39 |\n","|  3|       1|       1|Chips and Tomatil...|                null|    $2.39 |\n","|  4|       2|       2|        Chicken Bowl|[Tomatillo-Red Ch...|   $16.98 |\n","+---+--------+--------+--------------------+--------------------+----------+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["23/08/29 15:56:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n"," Header: , order_id, quantity, item_name, choice_description, item_price\n"," Schema: _c0, order_id, quantity, item_name, choice_description, item_price\n","Expected: _c0 but found: \n","CSV file: file:///home/sushan/Spark-Class/Day1/chipotle.csv\n"]}],"source":["# Method 1: Using show(5) to show top 5 data\n","df.show(5)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ENzcdIl6ngLh","outputId":"fe9e44cc-8c1f-4657-8af8-2f7526e73d61"},"outputs":[{"name":"stderr","output_type":"stream","text":["23/08/29 15:57:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n"," Header: , order_id, quantity, item_name, choice_description, item_price\n"," Schema: _c0, order_id, quantity, item_name, choice_description, item_price\n","Expected: _c0 but found: \n","CSV file: file:///home/sushan/Spark-Class/Day1/chipotle.csv\n"]},{"name":"stdout","output_type":"stream","text":["+---+--------+--------+--------------------+------------------+----------+\n","|_c0|order_id|quantity|           item_name|choice_description|item_price|\n","+---+--------+--------+--------------------+------------------+----------+\n","|  0|       1|       1|Chips and Fresh T...|              null|    $2.39 |\n","|  1|       1|       1|                Izze|      [Clementine]|    $3.39 |\n","|  2|       1|       1|    Nantucket Nectar|           [Apple]|    $3.39 |\n","+---+--------+--------+--------------------+------------------+----------+\n","only showing top 3 rows\n","\n","_*__*__*__*__*__*__*__*__*_\n"," \n","+--------+--------------------+----------+\n","|order_id|           item_name|item_price|\n","+--------+--------------------+----------+\n","|       1|Chips and Fresh T...|    $2.39 |\n","|       1|                Izze|    $3.39 |\n","|       1|    Nantucket Nectar|    $3.39 |\n","+--------+--------------------+----------+\n","only showing top 3 rows\n","\n"]}],"source":["# Method 2: Using select with show() to show the data\n","df.select('*').show(3)\n","print(\"_*_\"*9)\n","print(\" \")\n","\n","# Showing specific columns from dataframe using select\n","df.select('order_id', 'item_name', 'item_price').show(3)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/sushan/spark-3.4.1-bin-hadoop3/python/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n","  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"]}],"source":["# creating table to perform sql queries on spark dataframe\n","df.registerTempTable('chipotle_table')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/08/29 15:57:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n"," Header: , order_id, quantity, item_name, choice_description, item_price\n"," Schema: _c0, order_id, quantity, item_name, choice_description, item_price\n","Expected: _c0 but found: \n","CSV file: file:///home/sushan/Spark-Class/Day1/chipotle.csv\n"]},{"name":"stdout","output_type":"stream","text":["+----+--------+--------+-------------------+--------------------+----------+\n","| _c0|order_id|quantity|          item_name|  choice_description|item_price|\n","+----+--------+--------+-------------------+--------------------+----------+\n","| 607|     250|       1|   Steak Salad Bowl|[Fresh Tomato Sal...|    $9.39 |\n","|3115|    1243|       1|Carnitas Salad Bowl|[Tomatillo Green ...|    $9.39 |\n","|1418|     576|       1|Barbacoa Salad Bowl|[Roasted Chili Co...|    $9.39 |\n","|1421|     576|       1|Barbacoa Salad Bowl|[Roasted Chili Co...|    $9.39 |\n","|1825|     738|       1|Barbacoa Salad Bowl|[Fresh Tomato Sal...|    $9.39 |\n","|1865|     756|       1|Carnitas Salad Bowl|[Fresh Tomato Sal...|    $9.39 |\n","|2600|    1032|       1|   Steak Salad Bowl|[Fresh Tomato Sal...|    $9.39 |\n","|2624|    1042|       1|   Steak Salad Bowl|[Fresh Tomato Sal...|    $9.39 |\n","|3098|    1235|       1|   Steak Salad Bowl|[Roasted Chili Co...|    $9.39 |\n","+----+--------+--------+-------------------+--------------------+----------+\n","\n"]}],"source":["# Using SQL queries on created table\n","spark.sql(\"SELECT * FROM chipotle_table ORDER BY item_price DESC LIMIT 9\").show()"]},{"cell_type":"markdown","metadata":{"id":"liKiPfy8ngLh"},"source":["### Step 4.Calculate basic statistics:\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ucLkr2RwngLh","outputId":"547d9f95-8b0b-4941-ee2e-2b828a57b4bf","scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["23/08/29 15:57:13 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","23/08/29 15:57:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n"," Header: , order_id, quantity, item_name, choice_description, item_price\n"," Schema: _c0, order_id, quantity, item_name, choice_description, item_price\n","Expected: _c0 but found: \n","CSV file: file:///home/sushan/Spark-Class/Day1/chipotle.csv\n","[Stage 6:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+-------+------------------+-----------------+------------------+-----------------+--------------------+----------+\n","|summary|               _c0|         order_id|          quantity|        item_name|  choice_description|item_price|\n","+-------+------------------+-----------------+------------------+-----------------+--------------------+----------+\n","|  count|              4622|             4622|              4622|             4622|                3376|      4622|\n","|   mean|            2310.5|927.2548680225011|1.0757247944612722|             null|                null|      null|\n","| stddev|1334.4008018582722|528.8907955866096|0.4101863342575333|             null|                null|      null|\n","|    min|                 0|                1|                 1|6 Pack Soft Drink|[Adobo-Marinated ...|    $1.09 |\n","|    max|              4621|             1834|                15|Veggie Soft Tacos|[[Tomatillo-Red C...|    $9.39 |\n","+-------+------------------+-----------------+------------------+-----------------+--------------------+----------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df.describe().show()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/08/29 15:57:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n"," Header: , order_id, quantity, item_name, choice_description, item_price\n"," Schema: _c0, order_id, quantity, item_name, choice_description, item_price\n","Expected: _c0 but found: \n","CSV file: file:///home/sushan/Spark-Class/Day1/chipotle.csv\n","[Stage 9:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+-------+------------------+-----------------+------------------+-----------------+--------------------+----------+\n","|summary|               _c0|         order_id|          quantity|        item_name|  choice_description|item_price|\n","+-------+------------------+-----------------+------------------+-----------------+--------------------+----------+\n","|  count|              4622|             4622|              4622|             4622|                3376|      4622|\n","|   mean|            2310.5|927.2548680225011|1.0757247944612722|             null|                null|      null|\n","| stddev|1334.4008018582722|528.8907955866096|0.4101863342575333|             null|                null|      null|\n","|    min|                 0|                1|                 1|6 Pack Soft Drink|[Adobo-Marinated ...|    $1.09 |\n","|    25%|              1155|              477|                 1|             null|                null|      null|\n","|    50%|              2310|              926|                 1|             null|                null|      null|\n","|    75%|              3466|             1393|                 1|             null|                null|      null|\n","|    max|              4621|             1834|                15|Veggie Soft Tacos|[[Tomatillo-Red C...|    $9.39 |\n","+-------+------------------+-----------------+------------------+-----------------+--------------------+----------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df.summary().show()"]},{"cell_type":"markdown","metadata":{"id":"y7UQ2Yg5ngLh"},"source":["### Step 5. What is the number of observations in the dataset?"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"J37y3eu0ngLh","outputId":"f7ba5f5e-5135-409a-c8ec-1d2afe3a2f15"},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of observations in dataframe is: 4622\n"]}],"source":["print(\"The number of observations in dataframe is:\", df.count())"]},{"cell_type":"markdown","metadata":{"id":"j0fc1IqnngLh"},"source":["### Step 6. What is the number of columns in the dataset?"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ZvrsnxdnngLh","outputId":"6abda964-24b5-43c9-bbb6-e8dc16580cd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["The number of columns in dataframe is: 6\n"]}],"source":["print(\"The number of columns in dataframe is:\", len(df.columns))"]},{"cell_type":"markdown","metadata":{"id":"f6UHKvXRngLi"},"source":["### Step 7. Print the name of all the columns."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Umq6X5rongLi","outputId":"71e43868-0c4c-4029-c48f-617a552d8883"},"outputs":[{"name":"stdout","output_type":"stream","text":["The name of columns in the spark df : \n"]},{"data":{"text/plain":["['_c0',\n"," 'order_id',\n"," 'quantity',\n"," 'item_name',\n"," 'choice_description',\n"," 'item_price']"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["print(\"The name of columns in the spark df : \")\n","df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
